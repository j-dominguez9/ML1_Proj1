{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Adults Dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Lab 3: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Richard Kim <br> Connor Dobbs<br> Joaquin Dominguez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Hide deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full, clean dataset with original attributes\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/j-dominguez9/ML1_Proj1/main/Data/census_clean.csv')\n",
    "\n",
    "\n",
    "# OneHotEncoded dataset\n",
    "df_ohe = pd.read_csv('https://raw.githubusercontent.com/j-dominguez9/ML1_Proj1/main/Data/OHE_Adults.csv')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we seperate the entire dataset into 'train' and 'test' with a 90/10 split. This 'test' set will be used as a hold out set for final evaluation after models have been hyperparameter tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40657\n"
     ]
    }
   ],
   "source": [
    "# create train, validation, and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "df_2 = df_ohe.copy()\n",
    "\n",
    "np.random.seed(42)\n",
    "train, test = np.split(df_2.sample(frac=1), [int(.9*len(df_2))])\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import relevant function\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "### acquire target label values, delete column of said acquired values, and assign remaining variables and corresponding values to 'X'\n",
    "\n",
    "if 'income' in train:\n",
    "    y_train = train['income'].values \n",
    "    del train['income'] \n",
    "    X_train = train.values \n",
    "\n",
    "\n",
    "# target label values for test set\n",
    "if 'income' in test:\n",
    "    y_test = test['income'].values \n",
    "    del test['income'] \n",
    "    X_test = test.values \n",
    "\n",
    "#create train2 to keep version with age\n",
    "train2 = train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Redo above for age variable as outcome\n",
    "\n",
    "if 'age' in train:\n",
    "    yAge_train = train['age'].values \n",
    "    del train['age'] \n",
    "    XAge_train = train.values \n",
    "\n",
    "if 'age' in test:\n",
    "    yAge_test = test['age'].values \n",
    "    del test['age'] \n",
    "    XAge_test = test.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize and Scale Data\n",
    "\n",
    "We will standardize the dataset to ensure that each variable is weighted equally, since there are many variables on very different scales as well as one hot encoded categorical variables. This should help reduce model bias, improving performance, as well as making feature importance easier to interpret later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#standard set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "X_train = scl_obj.transform(X_train) \n",
    "X_test = scl_obj.transform(X_test)\n",
    "\n",
    "#oversampled data \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_over)\n",
    "X_over = scl_obj.transform(X_over) \n",
    "X_test_over = scl_obj.transform(X_test)\n",
    "\n",
    "#undersampled data\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_under)\n",
    "X_under = scl_obj.transform(X_under) \n",
    "X_test_under = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "\n",
    "In data preparation, we seperated the entire dataset into 'train' and 'test' with a 80/20 split. This 'test' set will be used for final evaluation after models have been hyperparameter tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the 'train' set, we create a 10-fold shuffle split cross validation object that can be used with the regular, over, and under sampled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import relevant function\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "### split data 80/20 with 10 cross-validation\n",
    "num_cv_iterations = 10\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 42)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific\n",
    "dataset and the stakeholders needs?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and adjust parameters.\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and Compare\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Results\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the Ramifications\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have free reign to provide additional analyses or combine analyses.\n",
    "\n",
    "*Delete before submitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
