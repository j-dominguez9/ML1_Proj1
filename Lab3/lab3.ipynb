{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Adults Dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Lab 3: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Richard Kim <br> Connor Dobbs<br> Joaquin Dominguez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Hide deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full, clean dataset with original attributes\n",
    "df_clean = pd.read_csv('https://raw.githubusercontent.com/j-dominguez9/ML1_Proj1/main/Data/census_clean.csv')\n",
    "\n",
    "\n",
    "# OneHotEncoded dataset\n",
    "df_ohe = pd.read_csv('https://raw.githubusercontent.com/j-dominguez9/ML1_Proj1/main/Data/OHE_Adults.csv')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we seperate the entire dataset into 'train' and 'test' with a 90/10 split. This 'test' set will be used as a hold out set for final evaluation after models have been hyperparameter tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40657\n"
     ]
    }
   ],
   "source": [
    "# create train, validation, and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "df_2 = df_ohe.copy()\n",
    "\n",
    "np.random.seed(42)\n",
    "train, test = np.split(df_2.sample(frac=1), [int(.9*len(df_2))])\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import relevant function\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "### acquire target label values, delete column of said acquired values, and assign remaining variables and corresponding values to 'X'\n",
    "\n",
    "if 'income' in train:\n",
    "    y_train = train['income'].values \n",
    "    del train['income'] \n",
    "    X_train = train.values \n",
    "\n",
    "\n",
    "# target label values for test set\n",
    "if 'income' in test:\n",
    "    y_test = test['income'].values \n",
    "    del test['income'] \n",
    "    X_test = test.values \n",
    "\n",
    "#create train2 to keep version with age\n",
    "train2 = train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Redo above for age variable as outcome\n",
    "\n",
    "if 'age' in train:\n",
    "    yAge_train = train['age'].values \n",
    "    del train['age'] \n",
    "    XAge_train = train.values \n",
    "\n",
    "if 'age' in test:\n",
    "    yAge_test = test['age'].values \n",
    "    del test['age'] \n",
    "    XAge_test = test.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize and Scale Data\n",
    "\n",
    "We will standardize the dataset to ensure that each variable is weighted equally, since there are many variables on very different scales as well as one hot encoded categorical variables. This should help reduce model bias, improving performance, as well as making feature importance easier to interpret later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#standard set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "X_train = scl_obj.transform(X_train) \n",
    "X_test = scl_obj.transform(X_test)\n",
    "\n",
    "#oversampled data \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_over)\n",
    "X_over = scl_obj.transform(X_over) \n",
    "X_test_over = scl_obj.transform(X_test)\n",
    "\n",
    "#undersampled data\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_under)\n",
    "X_under = scl_obj.transform(X_under) \n",
    "X_test_under = scl_obj.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "\n",
    "In data preparation, we seperated the entire dataset into 'train' and 'test' with a 80/20 split. This 'test' set will be used for final evaluation after models have been hyperparameter tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the 'train' set, we create a 10-fold shuffle split cross validation object that can be used with the regular, over, and under sampled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import relevant function\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "### split data 80/20 with 10 cross-validation\n",
    "num_cv_iterations = 10\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2, random_state = 42)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific\n",
    "dataset and the stakeholders needs?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of Data:\n",
    "\n",
    "This data was originally collected as part of the 1994 US Census. According to census.gov, The purpose of the Census is for the government to better understand the demographics of the people living there and where a variety of metrics are trending. This information is used to help determine where and how to allocate federal and state funding. The raw data was then extracted and compiled by Barry Becker and is available on UCI's machine learning repository here: https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "Accuracy: <br>\n",
    "> The first metric we will be using is Accuracy. By accuracy, we mean \"the ratio of number of correct predictions to the total number of input samples.\"[^1] \n",
    "\n",
    "> Accuracy = Number of Correct Predictions/Total Number of Predictions Made\n",
    "\n",
    "> By balancing our datset with respect to our target variable, we took measures to maximize the value that this metric provides. For our dataset, accuracy will give us a measure of how maany instances are correctly classified as >=50K  or <50K, in any given model.\n",
    "\n",
    "Precision: <br>\n",
    "> In order to get a more detailed look at what accuracy represents, we first break down the metric into Precision and Recall. Precision, in essence, outlines the proportion of positive identifications was actually correct[^2].\n",
    "\n",
    "> Precision = True Positive/(True Positive + False Positive)\n",
    "\n",
    "> For our dataset, Precision will give us a measure of the proportion of positives (>=50K) were classified correctly.\n",
    "\n",
    "Sensitivity/Recall: <br>\n",
    "\n",
    "> Recall, on the other hand, measures the proportion of actual positives that  were identified correctly[^3].\n",
    "\n",
    "> Recall = True Positive/(True Positive + False Negative)\n",
    "\n",
    "> For our dataset, Recall will give us a measure of how many of the instances that were actually >=50K were classified as such by the model.\n",
    "\n",
    "Specificity: <br>\n",
    "> Inversely to the previous measure, specificity (True Negative Rate) refers to the \"proportion of negative data points that are correctly considered as negative, with respect to all negative data points.\"[^5]\n",
    "\n",
    "> Sensitivity = True Negative/(True Negative + False Positive)\n",
    "\n",
    "> For our dataset, specificity measures the proportion of actual <50K classified as such by a given model.\n",
    "\n",
    "While we will look at the above metrics for income classifcation, the primary metric we will be looking to optimize in this case is Sensitivity, as it is the more useful metric in many contexts because it is harder to predict because it is a minority of people, and because predicting high earners could be used for things like targeted marketing campaigns for high margin products. \n",
    "\n",
    "[^1]: https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "[^2]: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n",
    "[^3]: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n",
    "[^4]: https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "[^5]: https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "\n",
    "### Age Prediction Evaluation Metric\n",
    "RMSE: <br>\n",
    "> The main metric we will be using to evaluate our prediction models for age is RMSE, or root mean squared error. \n",
    "\n",
    "> The RMSE of a model will tell us how far our model predictions deviate from the actual values. For our dataset, RMSE will measure the standard deviation of our model's predicted age from the actual age. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Meaning and Type\n",
    "\n",
    "The dataset contains 48,842 observations with 15 total variables, for a total of 732,630 data elements. The below list contains each attribute definition based on the UCI archive and data type determined in the code below. \n",
    "\n",
    "* age (integer between 17 and 90): The age of the individaul observed.\n",
    "* workclass (object with 8 levels): The employment type of the individual. For example if they are self employed or government employed. \n",
    "* fnlwgt (integer between ~12,285 and ~1,490,400): The definition of this is slightly unclear, but generally seems to be the number of people the census estimates the observation represents. \n",
    "* education (object with 16 levels): Category of education completed by observation.\n",
    "* educational-num (integer between 1 and 16): Numeric value of education completed by observation. \n",
    "* marital-status (object with 7 levels): Marital status of individual, including if their spouse is in the armed forces or absent.\n",
    "* occupation (object with 14 levels): The type of work the indidividual does.\n",
    "* relationship (object with 6 levels): Relationship individual has with others in the househould, similar to marital status but includes other categories potentially more applicable to younger observations such as ownly child or not in a family. \n",
    "* race (object with 5 levels): Race of indivdual\n",
    "* sex (object with 2 levels): Sex of individual, male or female\n",
    "* capital-gain (integer between 0 and 99,999): Self-reported capital gains by the indidivdual for the most recent year.\n",
    "* capital-loss (integer between 0 and 4,356): Self-reported capital losses by the individual for the most recent year. \n",
    "* hours-per-week (integer between 1 and 99): Self-reported number of hours worked per week by the individual.\n",
    "* native-country (object with 42 levels): Native country of the individual\n",
    "* income (object with 2 levels): Self-reported income class for the individual, either greater or less than $50k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        46043 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       46033 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   47985 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "No.of.unique values in each column :\n",
      " age                   74\n",
      "workclass              8\n",
      "fnlwgt             28523\n",
      "education             16\n",
      "educational-num       16\n",
      "marital-status         7\n",
      "occupation            14\n",
      "relationship           6\n",
      "race                   5\n",
      "gender                 2\n",
      "capital-gain         123\n",
      "capital-loss          99\n",
      "hours-per-week        96\n",
      "native-country        41\n",
      "income                 2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/j-dominguez9/ML1_Proj1/main/Data/adult.csv') # read in the csv file\n",
    "\n",
    "#replace question mark values as na\n",
    "df = df.replace('?', np.NaN)\n",
    "\n",
    "df.info()\n",
    "\n",
    "# below method of finding count of unique values by column from: https://www.geeksforgeeks.org/how-to-count-distinct-values-of-a-pandas-dataframe-column/\n",
    "\n",
    "n = df.nunique(axis=0)\n",
    "  \n",
    "print(\"No.of.unique values in each column :\\n\",\n",
    "      n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "There are missing values in 3 of the columns: workclass, occupation, and native-country. \n",
    "\n",
    "While a missing value in occupation could indicate unemployed, it would then be expected to better align with the count of workclass in the level of \"never-worked\" and/or \"Without pay\", however this is not the case. \n",
    "\n",
    "It is also seen that all 2,799 missing workclass values are also missing an occupation. This pattern might suggest that they are unemployed, however they are still reporting working hours as well as at times income > $50k. \n",
    "\n",
    "The most likely explanation is a data collection or data quality issue for these two fields, since everyone should have a native country and class of work. With no clear pattern to these missing values, we will drop these records rather than trying to impute and potentially bias the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          2799\n",
       "fnlwgt                0\n",
       "education             0\n",
       "educational-num       0\n",
       "marital-status        0\n",
       "occupation         2809\n",
       "relationship          0\n",
       "race                  0\n",
       "gender                0\n",
       "capital-gain          0\n",
       "capital-loss          0\n",
       "hours-per-week        0\n",
       "native-country      857\n",
       "income                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count missing values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and adjust parameters.\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and Compare\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Results\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the Ramifications\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "*Delete before submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have free reign to provide additional analyses or combine analyses.\n",
    "\n",
    "*Delete before submitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
